<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="AISFormer">
  <meta property="og:title" content="AISFormer"/>
  <meta property="og:description" content="AISFormer"/>
  <meta property="og:url" content="https://uark-aicv.github.io/AISFormer"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="AISFormer">
  <meta name="twitter:description" content="AISFormer">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="AISFormer">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>AISFormer: Amodal Instance Segmentation with Transformer</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">AISFormer: Amodal Instance Segmentation with Transformer</h1>
            <div class="is-size-5 publication-authors">
                <!-- Paper authors -->
              <span class="author-block">
                <a href="https://trqminh.github.io/" target="_blank">Minh Tran</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="https://vhvkhoa.github.io/" target="_blank">Khoa Vo</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="https://kashu7100.github.io/" target="_blank">Kashu Yamazaki</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="" target="_blank">Arthur Fernandes</a><sup>2</sup>,
              </span>
              <span class="author-block">
                <a href="" target="_blank">Michael Kidd</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="https://uark-aicv.github.io/" target="_blank">Ngan Le</a><sup>1</sup>
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>University of Arkansas</span>&nbsp;&nbsp;&nbsp;
              <span class="author-block"><sup>2</sup>Cobb-Vantress, Inc</span>
              <br>
              <span class="author-block">BMVC 2022</span>
            </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/2210.06323" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/UARK-AICV/AISFormer" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Image carousel -->
<!-- <section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item"> -->
        <!-- Your image here -->
        <!-- <img src="static/images/aisformer/AIS_explain/AIS_explain-1.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          An explanation of different mask instances in Amodal Instance Segmentation (AIS). Given a region of interest (ROI) extracted by an object detector, AIS aims to extract both visible and invisible mask instances including occluder, visible, amodal, and invisible.
        </h2>
      </div>
      <div class="item"> -->
        <!-- Your image here -->
        <!-- <img src="static/images/aisformer/ISvsAIS/ISvsAIS-1.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          A comparison between Instance Segmentation (IS) and Amodal Instance Segmentation (AIS). Given an image with ROI (a), IS aims to extract the visible mask instance (b) whereas AIS aims to extract both the visible mask and occluded parts (c).
        </h2>
      </div>
      <div class="item"> -->
        <!-- Your image here -->
        <!-- <img src="static/images/aisformer/aistr-Flowchart/aistr-Flowchart-1.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          The overall flowchart of our proposed AISFormer. AISFormer consists of four modules corresponding to (i) feature encoding: after obtaining the region of interest (ROI) feature from the backbone and ROIAlign algorithm, CNN-based layers and a transformer encoder are applied to learn both short-range and long-range features of the given ROI.(ii) mask transformer decoding: generate the occluder, visible, and amodal mask query embeddings by a transformer decoder (iii) invisible mask embedding to model the coherence between the amodal and visible masks by computing the invisible mask embedding, and (iv) segmentation to estimate output masks including occluder, visible, amodal and invisible.
       </h2>
     </div>
  </div>
</div>
</div>
</section> -->
<!-- End image carousel -->


<!-- Network -->
<section class="section hero is-small">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <img src="static/images/aisformer/aistr-Flowchart/aistr-Flowchart-1.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          The overall flowchart of our proposed AISFormer, integrating feature encoding, mask decoding, invisible mask embedding, and segmentation to generate occluder, visible, amodal, and invisible masks.
       </h2>
      </div>
    </div>
  </div>
</section>



<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Amodal Instance Segmentation (AIS) aims to segment the region of both visible and possible occluded parts of an object instance. While Mask R-CNN-based AIS approaches have shown promising results, they are unable to model high-level features coherence due to the limited receptive field. The most recent transformer-based models show impressive performance on vision tasks, even better than Convolution Neural Networks (CNN). In this work, we present AISFormer, an AIS framework, with a Transformer-based mask head. AISFormer explicitly models the complex coherence between occluder, visible, amodal, and invisible masks within an object's regions of interest by treating them as learnable queries. Specifically, AISFormer contains four modules: (i) feature encoding: extract ROI and learn both short-range and long-range visual features. (ii) mask transformer decoding: generate the occluder, visible, and amodal mask query embeddings by a transformer decoder (iii) invisible mask embedding:  model the coherence between the amodal and visible masks, and (iv) mask predicting: estimate output masks including occluder, visible, amodal and invisible. We conduct extensive experiments and ablation studies on three challenging benchmarks i.e. KINS, D2SA, and COCOA-cls to evaluate the effectiveness of AISFormer. 
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->




<section class="section hero is-small">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Amodal Instance Segmentation (AIS)</h2>
        <img src="static/images/aisformer/AIS_explain/AIS_explain-1.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          An explanation of different mask instances in Amodal Instance Segmentation (AIS). Given a region of interest (ROI) extracted by an object detector, AIS aims to extract both visible and invisible mask instances including occluder, visible, amodal, and invisible.
        </h2>
        <img src="static/images/aisformer/ISvsAIS/ISvsAIS-1.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          A comparison between Instance Segmentation (IS) and Amodal Instance Segmentation (AIS). Given an image with ROI (a), IS aims to extract the visible mask instance (b) whereas AIS aims to extract both the visible mask and occluded parts (c).
        </h2>
      </div>
    </div>
  </div>
</section>


<!-- <section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <img src="static/images/aisformer/aistr-Encoder-Decoder/aistr-Encoder-Decoder-1.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          Illustration network architecture of AISFormer. (a): mask transformer encoder is designed as one block of self-attention, (b): mask transformer decoder is designed as a combination of one block of self-attention and one block of cross-attention and (c): invisible embedding is designed as an MLP with two hidden layers. 
        </h2>
      </div>
  </div>
</div>
</div>
</section> -->

<!-- Network -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">AISFormer Mask Head</h2>
        <img src="static/images/aisformer/aistr-Encoder-Decoder/aistr-Encoder-Decoder-1.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          Illustration network architecture of AISFormer. (a): mask transformer encoder is designed as one block of self-attention, (b): mask transformer decoder is designed as a combination of one block of self-attention and one block of cross-attention and (c): invisible embedding is designed as an MLP with two hidden layers. 
        </h2>
      </div>
    </div>
  </div>
</section>


<!-- Qualitative Results -->
<section class="hero is-small">
  <div class="hero-body has-text-centered">
    <h2 class="title is-3">Qualitative Results</h2>
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <!-- Your image here -->
        <img src="static/images/aisformer/D2SAQual/D2SAQual-1.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          Qualitative Results on D2SA dataset.
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/aisformer/KINSQual.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          Qualitative Results on KINS dataset.
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/aisformer/COCOAQual/COCOAQual-1.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          Qualitative Results on COCOA dataset.
       </h2>
     </div>
     <!-- <div class="item">
      <img src="static/images/aisformer/AttnVis/AttnVis-1.png" alt="MY ALT TEXT"/>
      <h2 class="subtitle has-text-centered">
        Attention map visualizations indicating the cross attention between our learnable queries and the corresponding region of interest.
      </h2>
    </div> -->
  </div>
</div>
</div>
</section>
<!-- End image carousel -->




<!-- Youtube video -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container"> -->
      <!-- Paper video. -->
      <!-- <h2 class="title is-3">Video Presentation</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          
          <div class="publication-video"> -->
            <!-- Youtube embed code here -->
            <!-- <iframe src="https://www.youtube.com/embed/JkaxUblCGz0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End youtube video -->


<!-- Video carousel -->
<!-- <section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Another Carousel</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-video1">
          <video poster="" id="video1" autoplay controls muted loop height="100%">
            <source src="static/videos/carousel1.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video2">
          <video poster="" id="video2" autoplay controls muted loop height="100%">
            <source src="static/videos/carousel2.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
          <video poster="" id="video3" autoplay controls muted loop height="100%">\
            <source src="static/videos/carousel3.mp4"
            type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End video carousel -->






<!-- Paper poster -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/sample.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section> -->
<!--End paper poster -->


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@article{tran2022aisformer,
        title={AISFormer: Amodal Instance Segmentation with Transformer},
        author={Tran, Minh and Vo, Khoa and Yamazaki, Kashu and Fernandes, Arthur and Kidd, Michael and Le, Ngan},
        journal={arXiv preprint arXiv:2210.06323},
        year={2022}
      }</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
    <!-- <h2 class="title">Acknowledgement</h2> -->
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This material is based upon work supported by the National Science Foundation (NSF) under Award No OIA-1946391, NSF 1920920, and NSF 2223793.
             <br><br>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page. This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
